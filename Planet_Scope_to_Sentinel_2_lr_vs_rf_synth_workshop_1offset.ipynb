{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PS_S2_fusion import (\n",
    "    rasterio,\n",
    "    NDVIDataLoader,\n",
    "    NDVIProcessor,\n",
    "    random,\n",
    "    Dict,\n",
    "    NDVIImage,\n",
    "    np,\n",
    "    LinearRegression,\n",
    "    RandomForestRegressor,\n",
    "    NDVIVisualizer,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global flag: Set to True to include before/after Sentinel-2 images as features, False to exclude\n",
    "INCLUDE_BEFORE_AFTER = False\n",
    "\n",
    "# global input and output dir settings\n",
    "input_dir = Path(\"D:/KiKompAg/Workshop/Data/clip_for_workshop/13\")\n",
    "output_dir = Path(\"D:/KiKompAg/Workshop/Data/output\")\n",
    "\n",
    "# input_dir = Path(\"./input/13\")\n",
    "# output_dir = Path(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tif(data, output_file, crs, transform):\n",
    "    \"\"\"Saves raster data to a GeoTIFF file.\n",
    "\n",
    "    Args:\n",
    "        data (array-like): The 2D or 3D raster data to save.\n",
    "        output_file (str): The path and filename of the output GeoTIFF file.\n",
    "        crs (str or rasterio.crs.CRS): The Coordinate Reference System.\n",
    "              Can be an EPSG code string (e.g., 'EPSG:4326')\n",
    "              or a rasterio.crs.CRS object.\n",
    "        transform (affine.Affine): The affine transformation for the raster.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine number of bands\n",
    "    if data.ndim == 2:\n",
    "        count = 1\n",
    "    elif data.ndim == 3:\n",
    "        count = data.shape[0]  # Assume bands are in the first dimension\n",
    "    else:\n",
    "        raise ValueError(\"Data must be 2D or 3D.\")\n",
    "\n",
    "    profile = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": data.shape[1] if data.ndim == 3 else data.shape[0],\n",
    "        \"width\": data.shape[2] if data.ndim == 3 else data.shape[1],\n",
    "        \"count\": count,\n",
    "        \"dtype\": data.dtype.name,  # Use data type of input data\n",
    "        \"crs\": crs,\n",
    "        \"transform\": transform,\n",
    "    }\n",
    "\n",
    "    with rasterio.open(output_file, \"w\", **profile) as dst:\n",
    "        if count == 1:\n",
    "            dst.write(data, 1)\n",
    "        else:\n",
    "            for band_index in range(1, count + 1):\n",
    "                dst.write(data[band_index - 1], band_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load NDVI data\n",
    "data_loader = NDVIDataLoader()\n",
    "processor = NDVIProcessor()\n",
    "\n",
    "shapefile_2021 = input_dir / \"2021/shp/2021_fid13_maize_subset.shp\"\n",
    "shapefile_2022 = input_dir / \"2022/shp/2022_fid13_maize_subset.shp\"\n",
    "\n",
    "sentinel_2_images_2021 = data_loader.load_ndvi_images(\n",
    "    input_dir / \"2021/ndvi/S2/\", \"S2*.tif\"\n",
    ")\n",
    "planet_scope_images_2021 = data_loader.load_ndvi_images(\n",
    "    input_dir / \"2021/ndvi/PS/\", \"PS*.tif\"\n",
    ")\n",
    "\n",
    "sentinel_2_images_2022 = data_loader.load_ndvi_images(\n",
    "    input_dir / \"2022/ndvi/S2/\", \"S2*.tif\"\n",
    ")\n",
    "planet_scope_images_2022 = data_loader.load_ndvi_images(\n",
    "    input_dir / \"2022/ndvi/PS/\", \"PS*.tif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_image_pairs(sentinel_images, planet_images, year):\n",
    "    \"\"\"\n",
    "    Finds matching image pairs from Sentinel-2 and PlanetScope dictionaries\n",
    "    based on DOY with a descriptive output.\n",
    "\n",
    "    Args:\n",
    "        sentinel_images: Dictionary with DOY as key and Sentinel-2 NDVI data as value.\n",
    "        planet_images: Dictionary with DOY as key and PlanetScope NDVI data as value.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, where each dictionary represents a match:\n",
    "            {'planet_doy': ...,\n",
    "             'sentinel_matching_doy': ...,\n",
    "             'sentinel_before_doy': ...,\n",
    "             'sentinel_after_doy': ...}\n",
    "    \"\"\"\n",
    "    matching_pairs = []\n",
    "\n",
    "    for planet_doy in planet_images:\n",
    "        for doy_offset in range(-1, 2):  # Check DOY Â± 3 days\n",
    "            matching_sentinel_doy = planet_doy + doy_offset\n",
    "            if matching_sentinel_doy in sentinel_images:\n",
    "                # Find nearest before/after Sentinel images\n",
    "                sentinel_before_doy = max(\n",
    "                    [doy for doy in sentinel_images if doy < matching_sentinel_doy]\n",
    "                )\n",
    "                sentinel_after_doy = min(\n",
    "                    [doy for doy in sentinel_images if doy > matching_sentinel_doy]\n",
    "                )\n",
    "                matching_pairs.append(\n",
    "                    {\n",
    "                        \"year\": year,\n",
    "                        \"planet_doy\": planet_doy,\n",
    "                        \"sentinel_matching_doy\": matching_sentinel_doy,\n",
    "                        \"sentinel_before_doy\": sentinel_before_doy,\n",
    "                        \"sentinel_after_doy\": sentinel_after_doy,\n",
    "                    }\n",
    "                )\n",
    "                break  # Move on to the next PlanetScope image after a match\n",
    "    return matching_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with your dictionaries:\n",
    "matching_pairs_2022 = find_matching_image_pairs(\n",
    "    sentinel_2_images_2022, planet_scope_images_2022, 2022\n",
    ")\n",
    "\n",
    "matching_pairs_2021 = find_matching_image_pairs(\n",
    "    sentinel_2_images_2021, planet_scope_images_2021, 2021\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_pairs = matching_pairs_2021 + matching_pairs_2022\n",
    "validation_pairs = random.sample(matching_pairs, 5)\n",
    "\n",
    "training_pairs = [\n",
    "    element for element in matching_pairs if element not in validation_pairs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matching_pairs_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_target_pair(\n",
    "    match,\n",
    "    sentinel_images: Dict[int, NDVIImage],\n",
    "    planet_images: Dict[int, NDVIImage],\n",
    "    shapefile_path: Path,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a single feature array (X) and target array (y) pair\n",
    "    for one set of matching images.\n",
    "\n",
    "    Args:\n",
    "        match: A single dictionary from the matching_pairs list.\n",
    "        sentinel_images: Dictionary with DOY as key and Sentinel-2 NDVIImage.\n",
    "        planet_images: Dictionary with DOY as key and PlanetScope NDVIImage.\n",
    "\n",
    "    Returns:\n",
    "        A tuple: (features (X), targets (y))\n",
    "            - features (X): 2D NumPy array of features, one row per valid pixel.\n",
    "            - targets (y): 1D NumPy array of corresponding Sentinel-2 NDVI.\n",
    "    \"\"\"\n",
    "    processor = NDVIProcessor()\n",
    "\n",
    "    year = match[\"year\"]\n",
    "    planet_doy = match[\"planet_doy\"]\n",
    "    sentinel_matching_doy = match[\"sentinel_matching_doy\"]\n",
    "    sentinel_before_doy = match[\"sentinel_before_doy\"]\n",
    "    sentinel_after_doy = match[\"sentinel_after_doy\"]\n",
    "\n",
    "    # Resample PlanetScope\n",
    "    planet_image = processor.resample_planet_to_sentinel(\n",
    "        sentinel_images[sentinel_matching_doy], planet_images[planet_doy]\n",
    "    )\n",
    "\n",
    "    # Extract pixel data\n",
    "    sentinel_matching_image = sentinel_images[sentinel_matching_doy]\n",
    "    sentinel_before_image = sentinel_images[sentinel_before_doy]\n",
    "    sentinel_after_image = sentinel_images[sentinel_after_doy]\n",
    "\n",
    "    # exclude maize\n",
    "    planet_image.ndvi = processor.mask_array_with_shapefile(\n",
    "        planet_image.ndvi, planet_image.transform, shapefile_path\n",
    "    )\n",
    "    sentinel_matching_image.ndvi = processor.mask_array_with_shapefile(\n",
    "        sentinel_matching_image.ndvi, sentinel_matching_image.transform, shapefile_path\n",
    "    )\n",
    "    sentinel_before_image.ndvi = processor.mask_array_with_shapefile(\n",
    "        sentinel_before_image.ndvi, sentinel_before_image.transform, shapefile_path\n",
    "    )\n",
    "    sentinel_after_image.ndvi = processor.mask_array_with_shapefile(\n",
    "        sentinel_after_image.ndvi, sentinel_after_image.transform, shapefile_path\n",
    "    )\n",
    "\n",
    "    # ... (Your processing with invalid_mask as before)\n",
    "    invalid_mask_matching = processor.get_invalid_mask(\n",
    "        sentinel_ndvi_data=sentinel_matching_image.ndvi,\n",
    "        planet_ndvi_data=planet_image.ndvi,\n",
    "    )\n",
    "\n",
    "    invalid_mask_before_after = processor.get_invalid_mask(\n",
    "        sentinel_before_image.ndvi, sentinel_after_image.ndvi\n",
    "    )\n",
    "\n",
    "    invalid_mask = np.logical_or(invalid_mask_matching, invalid_mask_before_after)\n",
    "    invalid_mask = invalid_mask_matching  # for +/-1 day offset\n",
    "\n",
    "    sentinel_matching_data = processor.get_preprocessed_ndiv_data(\n",
    "        sentinel_matching_image, invalid_mask\n",
    "    ).flatten()\n",
    "    if INCLUDE_BEFORE_AFTER:\n",
    "        sentinel_before_data = processor.get_preprocessed_ndiv_data(\n",
    "            sentinel_before_image, invalid_mask\n",
    "        ).flatten()\n",
    "        sentinel_after_data = processor.get_preprocessed_ndiv_data(\n",
    "            sentinel_after_image, invalid_mask\n",
    "        ).flatten()\n",
    "    planet_data = processor.get_preprocessed_ndiv_data(\n",
    "        planet_image, invalid_mask\n",
    "    ).flatten()\n",
    "\n",
    "    num_valid_pixels = len(sentinel_matching_data)\n",
    "\n",
    "    # Create feature matrix (one row per valid pixel)\n",
    "    if INCLUDE_BEFORE_AFTER:\n",
    "        features = np.column_stack(\n",
    "            (\n",
    "                planet_data,\n",
    "                sentinel_before_data,\n",
    "                sentinel_after_data,\n",
    "                np.full(num_valid_pixels, planet_doy),\n",
    "                np.full(num_valid_pixels, sentinel_before_doy),\n",
    "                np.full(num_valid_pixels, sentinel_after_doy),\n",
    "                np.full(num_valid_pixels, year),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        features = np.column_stack(\n",
    "            (\n",
    "                planet_data,\n",
    "                np.full(num_valid_pixels, planet_doy),\n",
    "                np.full(num_valid_pixels, year),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    targets = sentinel_matching_data\n",
    "\n",
    "    return features, targets, invalid_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Process data for each match in a loop\n",
    "all_features = []\n",
    "all_targets = []\n",
    "all_masks = []\n",
    "for match in training_pairs:\n",
    "    if match[\"year\"] == 2022:\n",
    "        X, y, invalid_mask = create_feature_target_pair(\n",
    "            match,\n",
    "            sentinel_2_images_2022,\n",
    "            planet_scope_images_2022,\n",
    "            shapefile_2022,\n",
    "        )\n",
    "    else:\n",
    "        X, y, invalid_mask = create_feature_target_pair(\n",
    "            match,\n",
    "            sentinel_2_images_2021,\n",
    "            planet_scope_images_2021,\n",
    "            shapefile_2021,\n",
    "        )\n",
    "\n",
    "    all_features.append(X)\n",
    "    all_targets.append(y)\n",
    "    all_masks.append(invalid_mask)\n",
    "\n",
    "# Concatenate the results if needed\n",
    "X = np.concatenate(all_features, axis=0)\n",
    "y = np.concatenate(all_targets)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=40, max_depth=15, random_state=42, n_jobs=8\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "all_masks = []\n",
    "for match in validation_pairs:\n",
    "    if match[\"year\"] == 2021:\n",
    "        X, y, invalid_mask = create_feature_target_pair(\n",
    "            match,\n",
    "            sentinel_2_images_2021,\n",
    "            planet_scope_images_2021,\n",
    "            shapefile_2021,\n",
    "        )\n",
    "    else:\n",
    "        X, y, invalid_mask = create_feature_target_pair(\n",
    "            match,\n",
    "            sentinel_2_images_2022,\n",
    "            planet_scope_images_2022,\n",
    "            shapefile_2022,\n",
    "        )\n",
    "    all_features.append(X)\n",
    "    all_targets.append(y)\n",
    "    all_masks.append(invalid_mask)\n",
    "\n",
    "# Evaluate and visualize within a single loop\n",
    "mse_dict_synth = {}\n",
    "mse_dict_resampled = {}\n",
    "mean_ndiv_dict_synth = {}\n",
    "mean_ndiv_dict_resampled = {}\n",
    "mean_ndiv_dict_real = {}\n",
    "visualizer = NDVIVisualizer()\n",
    "\n",
    "for i, match in enumerate(validation_pairs):\n",
    "    year = match[\"year\"]\n",
    "    if year == 2022:\n",
    "        sentinel_2_images = sentinel_2_images_2022\n",
    "        planet_scope_images = planet_scope_images_2022\n",
    "    else:\n",
    "        sentinel_2_images = sentinel_2_images_2021\n",
    "        planet_scope_images = planet_scope_images_2021\n",
    "\n",
    "    planet_doy = match[\"planet_doy\"]\n",
    "    sentinel_matching_doy = match[\"sentinel_matching_doy\"]\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = lr_model.predict(all_features[i])\n",
    "\n",
    "    # Create synthetic image\n",
    "    synth_image = copy.deepcopy(sentinel_2_images[sentinel_matching_doy])\n",
    "    synth_image.ndvi[~all_masks[i]] = predictions\n",
    "\n",
    "    #    save_tif(synth_image.ndvi, f\"output/{year}-{planet_doy}-linear.tif\", synth_image.crs, synth_image.transform)\n",
    "\n",
    "    # Resampled PlanetScope for comparison\n",
    "    resampled_image = processor.resample_planet_to_sentinel(\n",
    "        sentinel_2_images[sentinel_matching_doy],\n",
    "        planet_scope_images[planet_doy],\n",
    "    )\n",
    "    if year == 2022:\n",
    "        resampled_image.ndvi = processor.mask_array_with_shapefile(\n",
    "            resampled_image.ndvi, resampled_image.transform, shapefile_2022\n",
    "        )\n",
    "    else:\n",
    "        resampled_image.ndvi = processor.mask_array_with_shapefile(\n",
    "            resampled_image.ndvi, resampled_image.transform, shapefile_2021\n",
    "        )\n",
    "\n",
    "    # Visualize using your NDVIVisualizer\n",
    "    visualizer.visualize_ndvi_images(\n",
    "        sentinel_2_images[sentinel_matching_doy].ndvi,\n",
    "        synth_image.ndvi,\n",
    "        resampled_image.ndvi,\n",
    "        planet_doy,\n",
    "        year,\n",
    "    )\n",
    "\n",
    "    cropout_sentinel_2_ndvi = sentinel_2_images[sentinel_matching_doy].ndvi[\n",
    "        #        600:800, 1000:1200\n",
    "        300:500, 200:400\n",
    "    ]\n",
    "    cropout_synth_ndvi = synth_image.ndvi[300:500, 200:400]\n",
    "    cropout_resampled_ndvi = resampled_image.ndvi[300:500, 200:400]\n",
    "\n",
    "    visualizer.visualize_ndvi_images(\n",
    "        cropout_sentinel_2_ndvi,\n",
    "        cropout_synth_ndvi,\n",
    "        cropout_resampled_ndvi,\n",
    "        planet_doy,\n",
    "        year,\n",
    "    )\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse_synth = mean_squared_error(all_targets[i], predictions)\n",
    "\n",
    "    print(f\"Mean Squared Error for Synthetic Planetscope DOY {planet_doy}: {mse_synth}\")\n",
    "\n",
    "    mse_resampled = mean_squared_error(\n",
    "        all_targets[i],\n",
    "        processor.get_preprocessed_ndiv_data(resampled_image, all_masks[i]),\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Mean Squared Error for Resampled Planetscope DOY {planet_doy}: {mse_resampled}\"\n",
    "    )\n",
    "\n",
    "    mse_dict_synth[planet_doy] = mse_synth\n",
    "    mse_dict_resampled[planet_doy] = mse_resampled\n",
    "    mean_ndiv_dict_synth[planet_doy] = np.mean(predictions)\n",
    "    mean_ndiv_dict_resampled[planet_doy] = np.nanmean(resampled_image.ndvi)\n",
    "    mean_ndiv_dict_real[planet_doy] = np.nanmean(\n",
    "        sentinel_2_images[sentinel_matching_doy].ndvi\n",
    "    )\n",
    "\n",
    "\n",
    "visualizer.plot_time_series(\n",
    "    mse_dict_synth,\n",
    "    mse_dict_resampled,\n",
    "    mean_ndiv_dict_synth,\n",
    "    mean_ndiv_dict_resampled,\n",
    "    mean_ndiv_dict_real,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Error Resampled: {sum(mse_dict_resampled.values())}\")\n",
    "print(f\"Total Error Synthetic: {sum(mse_dict_synth.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "all_masks = []\n",
    "for match in validation_pairs:\n",
    "    if match[\"year\"] == 2021:\n",
    "        X, y, invalid_mask = create_feature_target_pair(\n",
    "            match, sentinel_2_images_2021, planet_scope_images_2021, shapefile_2021\n",
    "        )\n",
    "    else:\n",
    "        X, y, invalid_mask = create_feature_target_pair(\n",
    "            match, sentinel_2_images_2022, planet_scope_images_2022, shapefile_2022\n",
    "        )\n",
    "    all_features.append(X)\n",
    "    all_targets.append(y)\n",
    "    all_masks.append(invalid_mask)\n",
    "\n",
    "# Evaluate and visualize within a single loop\n",
    "mse_dict_synth = {}\n",
    "mse_dict_resampled = {}\n",
    "mean_ndiv_dict_synth = {}\n",
    "mean_ndiv_dict_resampled = {}\n",
    "mean_ndiv_dict_real = {}\n",
    "visualizer = NDVIVisualizer()\n",
    "\n",
    "for i, match in enumerate(validation_pairs):\n",
    "    year = match[\"year\"]\n",
    "    if year == 2022:\n",
    "        sentinel_2_images = sentinel_2_images_2022\n",
    "        planet_scope_images = planet_scope_images_2022\n",
    "    else:\n",
    "        sentinel_2_images = sentinel_2_images_2021\n",
    "        planet_scope_images = planet_scope_images_2021\n",
    "\n",
    "    planet_doy = match[\"planet_doy\"]\n",
    "    sentinel_matching_doy = match[\"sentinel_matching_doy\"]\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = rf_model.predict(all_features[i])\n",
    "\n",
    "    # Create synthetic image\n",
    "    synth_image = copy.deepcopy(sentinel_2_images[sentinel_matching_doy])\n",
    "    synth_image.ndvi[~all_masks[i]] = predictions\n",
    "\n",
    "    #    save_tif(synth_image.ndvi, f\"output/{year}-{planet_doy}-random-forest.tif\", synth_image.crs, synth_image.transform)\n",
    "\n",
    "    # Resampled PlanetScope for comparison\n",
    "    resampled_image = processor.resample_planet_to_sentinel(\n",
    "        sentinel_2_images[sentinel_matching_doy],\n",
    "        planet_scope_images[planet_doy],\n",
    "    )\n",
    "    if year == 2022:\n",
    "        resampled_image.ndvi = processor.mask_array_with_shapefile(\n",
    "            resampled_image.ndvi, resampled_image.transform, shapefile_2022\n",
    "        )\n",
    "    else:\n",
    "        resampled_image.ndvi = processor.mask_array_with_shapefile(\n",
    "            resampled_image.ndvi, resampled_image.transform, shapefile_2021\n",
    "        )\n",
    "\n",
    "    # Visualize using your NDVIVisualizer\n",
    "    visualizer.visualize_ndvi_images(\n",
    "        sentinel_2_images[sentinel_matching_doy].ndvi,\n",
    "        synth_image.ndvi,\n",
    "        resampled_image.ndvi,\n",
    "        planet_doy,\n",
    "        year,\n",
    "    )\n",
    "\n",
    "    cropout_sentinel_2_ndvi = sentinel_2_images[sentinel_matching_doy].ndvi[\n",
    "        300:500, 200:400\n",
    "    ]\n",
    "    cropout_synth_ndvi = synth_image.ndvi[300:500, 200:400]\n",
    "    cropout_resampled_ndvi = resampled_image.ndvi[300:500, 200:400]\n",
    "\n",
    "    visualizer.visualize_ndvi_images(\n",
    "        cropout_sentinel_2_ndvi,\n",
    "        cropout_synth_ndvi,\n",
    "        cropout_resampled_ndvi,\n",
    "        planet_doy,\n",
    "        year,\n",
    "    )\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse_synth = mean_squared_error(all_targets[i], predictions)\n",
    "\n",
    "    print(f\"Mean Squared Error for Synthetic Planetscope DOY {planet_doy}: {mse_synth}\")\n",
    "\n",
    "    mse_resampled = mean_squared_error(\n",
    "        all_targets[i],\n",
    "        processor.get_preprocessed_ndiv_data(resampled_image, all_masks[i]),\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Mean Squared Error for Resampled Planetscope DOY {planet_doy}: {mse_resampled}\"\n",
    "    )\n",
    "\n",
    "    mse_dict_synth[planet_doy] = mse_synth\n",
    "    mse_dict_resampled[planet_doy] = mse_resampled\n",
    "    mean_ndiv_dict_synth[planet_doy] = np.mean(predictions)\n",
    "    mean_ndiv_dict_resampled[planet_doy] = np.nanmean(resampled_image.ndvi)\n",
    "    mean_ndiv_dict_real[planet_doy] = np.nanmean(\n",
    "        sentinel_2_images[sentinel_matching_doy].ndvi\n",
    "    )\n",
    "\n",
    "\n",
    "visualizer.plot_time_series(\n",
    "    mse_dict_synth,\n",
    "    mse_dict_resampled,\n",
    "    mean_ndiv_dict_synth,\n",
    "    mean_ndiv_dict_resampled,\n",
    "    mean_ndiv_dict_real,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Error Resampled: {sum(mse_dict_resampled.values())}\")\n",
    "print(f\"Total Error Synthetic: {sum(mse_dict_synth.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Here on run this after training the model to load and synthesize/merge all images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_sentinel_images(sentinel_images, planet_images, year):\n",
    "    \"\"\"\n",
    "    Finds matching image pairs from Sentinel-2 and PlanetScope dictionaries\n",
    "    based on DOY with a descriptive output.\n",
    "\n",
    "    Args:\n",
    "        sentinel_images: Dictionary with DOY as key and Sentinel-2 NDVI data as value.\n",
    "        planet_images: Dictionary with DOY as key and PlanetScope NDVI data as value.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, where each dictionary represents a match:\n",
    "            {'planet_doy': ...,\n",
    "             'sentinel_before_doy': ...,\n",
    "             'sentinel_after_doy': ...}\n",
    "    \"\"\"\n",
    "    set_of_input_images = []\n",
    "\n",
    "    for planet_doy in planet_images.keys():\n",
    "        ## Find nearest before/after Sentinel images\n",
    "        sentinel_before_doy = max([doy for doy in sentinel_images if doy < planet_doy])\n",
    "        sentinel_after_doy = min([doy for doy in sentinel_images if doy > planet_doy])\n",
    "        set_of_input_images.append(\n",
    "            {\n",
    "                \"year\": year,\n",
    "                \"planet_doy\": planet_doy,\n",
    "                \"sentinel_before_doy\": sentinel_before_doy,\n",
    "                \"sentinel_after_doy\": sentinel_after_doy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return set_of_input_images\n",
    "\n",
    "\n",
    "# Here we get all input images. The Planetscope image and both of the closes sentinel 2 images to predict the image after resampling\n",
    "set_of_input_images_2021 = find_closest_sentinel_images(\n",
    "    sentinel_2_images_2021, planet_scope_images_2021, 2021\n",
    ")\n",
    "set_of_input_images_2022 = find_closest_sentinel_images(\n",
    "    sentinel_2_images_2022, planet_scope_images_2022, 2022\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set_of_input_images_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_data(\n",
    "    match,\n",
    "    sentinel_images: Dict[int, NDVIImage],\n",
    "    planet_images: Dict[int, NDVIImage],\n",
    "    shapefile_path: Path,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a single feature array (X) and target array (y) pair\n",
    "    for one set of matching images.\n",
    "\n",
    "    Args:\n",
    "        match: A single dictionary from the matching_pairs list.\n",
    "        sentinel_images: Dictionary with DOY as key and Sentinel-2 NDVIImage.\n",
    "        planet_images: Dictionary with DOY as key and PlanetScope NDVIImage.\n",
    "\n",
    "    Returns:\n",
    "        A tuple: (features (X), targets (y))\n",
    "            - features (X): 2D NumPy array of features, one row per valid pixel.\n",
    "            - targets (y): 1D NumPy array of corresponding Sentinel-2 NDVI.\n",
    "    \"\"\"\n",
    "    processor = NDVIProcessor()\n",
    "\n",
    "    year = match[\"year\"]\n",
    "    planet_doy = match[\"planet_doy\"]\n",
    "    sentinel_before_doy = match[\"sentinel_before_doy\"]\n",
    "    sentinel_after_doy = match[\"sentinel_after_doy\"]\n",
    "\n",
    "    # Resample PlanetScope\n",
    "    planet_image = processor.resample_planet_to_sentinel(\n",
    "        sentinel_images[sentinel_before_doy], planet_images[planet_doy]\n",
    "    )\n",
    "\n",
    "    # Extract pixel data\n",
    "    sentinel_before_image = sentinel_images[sentinel_before_doy]\n",
    "    sentinel_after_image = sentinel_images[sentinel_after_doy]\n",
    "\n",
    "    # include maize\n",
    "    planet_image.ndvi = processor.mask_array_with_shapefile(\n",
    "        planet_image.ndvi, planet_image.transform, shapefile_path\n",
    "    )\n",
    "\n",
    "    sentinel_before_image.ndvi = processor.mask_array_with_shapefile(\n",
    "        sentinel_before_image.ndvi, sentinel_before_image.transform, shapefile_path\n",
    "    )\n",
    "    sentinel_after_image.ndvi = processor.mask_array_with_shapefile(\n",
    "        sentinel_after_image.ndvi, sentinel_after_image.transform, shapefile_path\n",
    "    )\n",
    "\n",
    "    invalid_mask_matching = processor.get_invalid_mask(\n",
    "        sentinel_ndvi_data=sentinel_before_image.ndvi,\n",
    "        planet_ndvi_data=planet_image.ndvi,\n",
    "    )\n",
    "\n",
    "    invalid_mask_before_after = processor.get_invalid_mask(\n",
    "        sentinel_before_image.ndvi, sentinel_after_image.ndvi\n",
    "    )\n",
    "\n",
    "    invalid_mask = np.logical_or(invalid_mask_matching, invalid_mask_before_after)\n",
    "    invalid_mask = invalid_mask_matching\n",
    "\n",
    "    if INCLUDE_BEFORE_AFTER:\n",
    "        sentinel_before_data = processor.get_preprocessed_ndiv_data(\n",
    "            sentinel_before_image, invalid_mask\n",
    "        ).flatten()\n",
    "        sentinel_after_data = processor.get_preprocessed_ndiv_data(\n",
    "            sentinel_after_image, invalid_mask\n",
    "        ).flatten()\n",
    "    planet_data = processor.get_preprocessed_ndiv_data(\n",
    "        planet_image, invalid_mask\n",
    "    ).flatten()\n",
    "\n",
    "    num_valid_pixels = (\n",
    "        len(sentinel_before_data) if INCLUDE_BEFORE_AFTER else len(planet_data)\n",
    "    )\n",
    "\n",
    "    # Create feature matrix (one row per valid pixel)\n",
    "    if INCLUDE_BEFORE_AFTER:\n",
    "        features = np.column_stack(\n",
    "            (\n",
    "                planet_data,\n",
    "                sentinel_before_data,\n",
    "                sentinel_after_data,\n",
    "                np.full(num_valid_pixels, planet_doy),\n",
    "                np.full(num_valid_pixels, sentinel_before_doy),\n",
    "                np.full(num_valid_pixels, sentinel_after_doy),\n",
    "                np.full(num_valid_pixels, year),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        features = np.column_stack(\n",
    "            (\n",
    "                planet_data,\n",
    "                np.full(num_valid_pixels, planet_doy),\n",
    "                np.full(num_valid_pixels, year),\n",
    "            )\n",
    "        )\n",
    "    return features, invalid_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = set_of_input_images_2021 + set_of_input_images_2022\n",
    "\n",
    "# Example usage: Process data for each match in a loop\n",
    "all_inputs = []\n",
    "all_masks = []\n",
    "for match in input_images:\n",
    "    if match[\"year\"] == 2022:\n",
    "        X, invalid_mask = create_input_data(\n",
    "            match,\n",
    "            sentinel_2_images_2022,\n",
    "            planet_scope_images_2022,\n",
    "            shapefile_2022,\n",
    "        )\n",
    "    else:\n",
    "        X, invalid_mask = create_input_data(\n",
    "            match,\n",
    "            sentinel_2_images_2021,\n",
    "            planet_scope_images_2021,\n",
    "            shapefile_2021,\n",
    "        )\n",
    "\n",
    "    all_inputs.append(X)\n",
    "    all_masks.append(invalid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "for i, match in enumerate(input_images):\n",
    "    year = match[\"year\"]\n",
    "    if year == 2022:\n",
    "        sentinel_2_images = sentinel_2_images_2022\n",
    "        planet_scope_images = planet_scope_images_2022\n",
    "    else:\n",
    "        sentinel_2_images = sentinel_2_images_2021\n",
    "        planet_scope_images = planet_scope_images_2021\n",
    "\n",
    "    planet_doy = match[\"planet_doy\"]\n",
    "    sentinel_before_doy = match[\"sentinel_before_doy\"]\n",
    "\n",
    "    # Only synthesize if there is NOT a Sentinel-2 image for this DOY\n",
    "    if planet_doy not in sentinel_2_images:\n",
    "        # Make predictions\n",
    "        predictions = rf_model.predict(all_inputs[i])\n",
    "\n",
    "        # Use the correct reference image for output\n",
    "        if INCLUDE_BEFORE_AFTER:\n",
    "            synth_image = copy.deepcopy(sentinel_2_images[sentinel_before_doy])\n",
    "        else:\n",
    "            # If not using before/after, still need a reference image; use before_doy as default\n",
    "            synth_image = copy.deepcopy(sentinel_2_images[sentinel_before_doy])\n",
    "\n",
    "        synth_image.ndvi[~all_masks[i]] = predictions\n",
    "\n",
    "        save_tif(\n",
    "            synth_image.ndvi,\n",
    "            output_dir / f\"Synth-rf_ndvi_doy_{year}_{planet_doy:03d}_.tif\",\n",
    "            synth_image.crs,\n",
    "            synth_image.transform,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
